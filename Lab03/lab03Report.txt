As usual, the Computerphile video was highly appreciated. I'm always down to watch however many hours of that wonderful channel. I knew he was getting us prepared for the "gotcha" moment, but the one that really messed with me was going in reverse on arrays.
I hadn't even considered that requesting information from the memory every single iteration was that taxing. Big O notation has us assume that arrays are faster since the memory is all in one place and we just simply iterate along it. When the CPU is slower than the memory, your program doesn't have to wait every single time it references something in memory, the data is just ready. With a CPU that runs faster than your memory clock speed, the program has to wait for the memory. 
However, the reason modern CPUs run array iterations faster (other than modern compiler optimizations) is the CPU cache, which reads based on cache lines; this returns more data at once. With old processors such as the Atari, linked lists run faster since the data is already pre-calculated in memory (and ready when the CPU asks for it due to CPU speed). Modern CPUs are much faster than memory, and traversing a linked list takes longer since it cannot be cached and the program has to wait for the memory. 
The Atari defies our assumption about Big O notation since it does not take into account how slow the hardware really is, and traversing a linked list is faster since the next place in memory is already pre-calculated. The thing that really got me was going backwards, but its simply an instruction oddity with machine language (I believe he said assembly).